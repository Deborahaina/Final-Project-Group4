{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, precision_score, recall_score, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils import data\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_PATH = os.getcwd()\n",
    "PATH = OR_PATH + os.path.sep + \"Deborah\" + os.path.sep + \"Final-Project-Group4\"\n",
    "\n",
    "FILENAME = PATH + os.path.sep + \"dataset\" + os.path.sep + \"final_dataset.xlsx\"\n",
    "DATA_DIR = PATH + os.path.sep + \"dataset\" + os.path.sep + \"train\" + os.path.sep\n",
    "ATTRIBUTES_DIR = PATH + os.path.sep + \"dataset\" + os.path.sep + \"attributes.xlsx\"\n",
    "\n",
    "#Inception net must have image sizes as 299 * 299\n",
    "n_epoch = 5\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0005\n",
    "\n",
    "## Image processing\n",
    "CHANNELS = 3\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "NICKNAME = \"Group4\"\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "THRESHOLD = 0.5\n",
    "SAVE_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_data = pd.read_excel(ATTRIBUTES_DIR)\n",
    "attributes = attr_data['name']\n",
    "\n",
    "\n",
    "#main data\n",
    "xdf_data = pd.read_excel(FILENAME)\n",
    "\n",
    "xdf_dtrain = xdf_data[xdf_data['Split'] == 'train'].copy()\n",
    "xdf_dtest = xdf_data[xdf_data['Split'] == 'test'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to process attributes features\n",
    "def preprocess_attributes(attributes):\n",
    "    attributes = attributes.to_list()\n",
    "    num_attribute_classes = len(attribute_map)\n",
    "    attribute_vectors = []\n",
    "    \n",
    "    for attr_string in attributes:\n",
    "        attribute_vector = torch.zeros(num_attribute_classes)\n",
    "        for attr_index, attr_names in attribute_map.items():\n",
    "            if attr_string in attr_names.split(', '):\n",
    "                attribute_vector[attr_index] = 1\n",
    "        attribute_vectors.append(attribute_vector)\n",
    "    \n",
    "    return attribute_vectors\n",
    "\n",
    "\n",
    "attribute_map = attributes.to_dict()\n",
    "preprocess_attributes(attributes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Custom data class to read in the images one sample at a time using the image ImageId\n",
    "\n",
    "    Processing the multilabel target(catgeory) into one-hot-encoding\n",
    "    \n",
    "    Returns the transformed images and labels\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class ImageDataset(data.Dataset):\n",
    "    def __init__(self, list_IDs, type_data, target_type):\n",
    "        #Initialization'\n",
    "        self.type_data = type_data\n",
    "        self.list_IDs = list_IDs\n",
    "        self.target_type = target_type\n",
    "        \n",
    "        self.transforms = v2.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            v2.CenterCrop(224),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0),\n",
    "            transforms.RandomGrayscale([0.2]),\n",
    "            v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "    #Denotes the total number of samples'  \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #Genrate one sample at a time by using loading the image file and the id\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "\n",
    "        if self.type_data == 'train':\n",
    "            y = xdf_dtrain.target_class.get(ID)\n",
    "            if self.target_type == 2:\n",
    "                y = y.split(\",\")\n",
    "        else:\n",
    "            y = xdf_dtest.target_class.get(ID)\n",
    "            if self.target_type == 2:\n",
    "                y = y.split(\",\")\n",
    "\n",
    "\n",
    "        if self.target_type == 2:\n",
    "            labels_ohe = [ int(e) for e in y]\n",
    "        else:\n",
    "            labels_ohe = np.zeros(OUTPUTS_a)\n",
    "\n",
    "            for idx, label in enumerate(range(OUTPUTS_a)):\n",
    "                if label == y:\n",
    "                    labels_ohe[idx] = 1\n",
    "\n",
    "        y = torch.FloatTensor(labels_ohe)\n",
    "\n",
    "        if self.type_data == 'train':\n",
    "            file = DATA_DIR + xdf_dtrain.ImageId.get(ID)\n",
    "        else:\n",
    "            file = DATA_DIR + xdf_dtest.ImageId.get(ID)\n",
    "\n",
    "        img = cv2.imread(file)\n",
    "\n",
    "        img= cv2.resize(img,(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        # Augmentation for training\n",
    "        X = torch.FloatTensor(img)\n",
    "\n",
    "        X = torch.reshape(X, (3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        if self.type_data == 'train':\n",
    "            X = self.transforms(X)\n",
    "\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_target(target_type):\n",
    "    '''\n",
    "        1- Binary   target = (1,0)\n",
    "        2- Multiclass  target = (1...n, text1...textn)\n",
    "        3- Multilabel target = ( list(Text1, Text2, Text3 ) for each observation, separated by commas )\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    dict_target = {}\n",
    "    xerror = 0\n",
    "\n",
    "    if target_type == 2:\n",
    "        ## The target comes as a string  x1, x2, x3,x4\n",
    "        ## the following code creates a list\n",
    "        target = np.array(xdf_data['Category'].apply( lambda x : x.split(\",\")))\n",
    "        final_target = mlb.fit_transform(target)\n",
    "        xfinal = []\n",
    "        if len(final_target) ==0:\n",
    "            xerror = 'Could not process Multilabel'\n",
    "        else:\n",
    "            class_names = mlb.classes_\n",
    "            for i in range(len(final_target)):\n",
    "                joined_string = \",\".join( str(e) for e in final_target[i])\n",
    "                xfinal.append(joined_string)\n",
    "            xdf_data['target_class'] = xfinal\n",
    "\n",
    "    if target_type == 1:\n",
    "        xtarget = list(np.array(xdf_data['Category'].unique()))\n",
    "        le = LabelEncoder()\n",
    "        le.fit(xtarget)\n",
    "        final_target = le.transform(np.array(xdf_data['Category']))\n",
    "        class_names=(xtarget)\n",
    "        xdf_data['target_class'] = final_target\n",
    "        \n",
    "        \n",
    "    ## Calculate class weights based on the frequency of each class in the dataset, finally worked!!!\n",
    "    label_matrix = xdf_dtrain['Category'].str.get_dummies(\",\")\n",
    "    class_dist = label_matrix.sum()\n",
    "    total_num_samples = class_dist.sum()\n",
    "    class_weights = total_num_samples / (class_dist * len(class_dist))\n",
    "    class_weight_tensor = torch.tensor(class_weights.values, dtype=torch.float)\n",
    "    sample_weights = label_matrix.dot(class_weight_tensor).values\n",
    "\n",
    "    return class_names, sample_weights\n",
    "    \n",
    "\n",
    "class_names, sample_weights = process_target(2)\n",
    "OUTPUTS_a = len(class_names)\n",
    "\n",
    "\n",
    "xdf_dtrain = xdf_data[xdf_data['Split'] == 'train'].copy()\n",
    "xdf_dtest = xdf_data[xdf_data['Split'] == 'test'].copy()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
